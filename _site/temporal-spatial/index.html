<!DOCTYPE html>
<html lang="en">
<head>
	<title>STUDIO FOR NARRATIVE SPACES / From Temporal to Spatial</title>
	<meta name="author" content="STUDIO FOR NARRATIVE SPACES">
	<meta name="description" content="Performance artforms like Peking opera face transmission challenges due to the extensive passive listening required to understand their nuance. To create engaging forms of experiencing auditory Intangible Cultural Heritage (ICH), we designed a spatial interactionbased segmented-audio (SISA) Virtual Reality system that transforms passive ICH experiences into active ones. We undertook: (1) a co-design workshop with seven stakeholders to establish design requirements, (2) prototyping with five participants to validate design elements, and (3) user testing with 16 participants exploring Peking Opera. We designed transformations of temporal music into spatial interactions by cutting sounds into short audio segments, applying t-SNE algorithm to cluster audio segments spatially. Users navigate through these sounds by their similarity in audio property. Analysis revealed two distinct interaction patterns (Progressive and Adaptive), and demonstrated SISA's efficacy in facilitating active auditory ICH engagement. Our work illuminates the design process for enriching traditional performance artform using spatially-tuned forms of listening.This temporal-to-spatial strategy was applied to a VR artwork shown at Osage Gallery in Hong Kong. In dreams, one's life experiences are jumbled together, so that characters can represent multiple people in your life and sounds can run together without sequential order. To show one's memories in a dream in a more contextual way, we represent environments and sounds using machine learning approaches that take into account the totality of a complex dataset. The immersive environment uses machine learning to computationally cluster sounds in thematic scenes to allow audiences to grasp the dimensions of the complexity in a dream-like scenario. We applied the t-SNE algorithm to collections of music and voice sequences to explore the way interactions in immersive space can be used to convert temporal sound data into spatial interactions. We designed both 2D and 3D interactions, as well as headspace vs. controller interactions in two case studies, one on segmenting a single work of music and one on a collection of sound fragments, applying it to a Virtual Reality (VR) artwork about replaying memories in a dream. We found that audiences can enrich their experience of the story without necessarily gaining an understanding of the artwork through the machine-learning generated soundscapes. This provides a method for experiencing the temporal sound sequences in an environment spatially using nonlinear exploration in VR.Honorable Mention Award Publication in DIS: Designing Interactive Systems (DIS'25), arxiv.Art Paper in EAI Conference: ArtsIT 2022.Exhibition at JCCAC and Osage Gallery Hong Kong.">
	<meta name="keywords" content="vr ar, hci, social good, machine learning">
	<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="robots" content="index,follow">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="/assets/css/style.css">
</head>
<body>
	<header class="header">
	<div class="container">
		<h1 class="logo">
			<a href="/">STUDIO FOR NARRATIVE SPACES</a>
		</h1>
	</div>
</header>
	<main class="content">
		<section class="project">
			<div class="container">
				<article>
					<span class="h2">Project</span>
					<h1>
						<a href="https://recfro.github.io/threeminds/soundoff/">From Temporal to Spatial</a>
					</h1>
					<span class="h2">Summary</span>
					<p>
Performance artforms like Peking opera face transmission challenges due to the extensive passive listening required to understand their nuance. To create engaging forms of experiencing auditory Intangible Cultural Heritage (ICH), we designed a spatial interactionbased segmented-audio (SISA) Virtual Reality system that transforms passive ICH experiences into active ones. We undertook: (1) a co-design workshop with seven stakeholders to establish design requirements, (2) prototyping with five participants to validate design elements, and (3) user testing with 16 participants exploring Peking Opera. We designed transformations of temporal music into spatial interactions by cutting sounds into short audio segments, applying t-SNE algorithm to cluster audio segments spatially. Users navigate through these sounds by their similarity in audio property. Analysis revealed two distinct interaction patterns (Progressive and Adaptive), and demonstrated SISA's efficacy in facilitating active auditory ICH engagement. Our work illuminates the design process for enriching traditional performance artform using spatially-tuned forms of listening.<br /><br />

This temporal-to-spatial strategy was applied to a VR artwork shown at Osage Gallery in Hong Kong. In dreams, one's life experiences are jumbled together, so that characters can represent multiple people in your life and sounds can run together without sequential order. To show one's memories in a dream in a more contextual way, we represent environments and sounds using machine learning approaches that take into account the totality of a complex dataset. The immersive environment uses machine learning to computationally cluster sounds in thematic scenes to allow audiences to grasp the dimensions of the complexity in a dream-like scenario. We applied the t-SNE algorithm to collections of music and voice sequences to explore the way interactions in immersive space can be used to convert temporal sound data into spatial interactions. We designed both 2D and 3D interactions, as well as headspace vs. controller interactions in two case studies, one on segmenting a single work of music and one on a collection of sound fragments, applying it to a Virtual Reality (VR) artwork about replaying memories in a dream. We found that audiences can enrich their experience of the story without necessarily gaining an understanding of the artwork through the machine-learning generated soundscapes. This provides a method for experiencing the temporal sound sequences in an environment spatially using nonlinear exploration in VR.<br /><br />

Honorable Mention Award Publication in DIS: <a href="https://doi.org/10.1145/3715336.3735787"><u>Designing Interactive Systems (DIS'25)</u></a>, <a href="https://arxiv.org/abs/2505.18112"><u>arxiv</u></a>.<br />
Art Paper in EAI Conference: <a href="https://link.springer.com/chapter/10.1007/978-3-030-95531-1_23"><u>ArtsIT 2022</u></a>.<br />
Exhibition at <a href="https://recfro.github.io/threeminds/"><u>JCCAC</u></a> and <a href="https://recfro.github.io/threeminds/soundoff/"><u>Osage Gallery Hong Kong</u></a>.</p>

					<div class="project-meta">
						<span class="h2">People</span>
						<p>RAY LC, Yuqi Wang, Sirui Wang, Shiman Zhang, Kexue Fu, Michelle Lui, Zeynep Erol, Zhiyuan Zhang, Eray Ozgunay</p>
						<span class="h2">Tech</span>
						<p>vr ar, hci, social good, machine learning</p>
						<span class="h2">Venues</span>
						<p><a title="DIS, Osage Gallery, EAI ArtsIT, JCCAC, Floating Projects" href="https://recfro.github.io/threeminds/soundoff/">DIS, Osage Gallery, EAI ArtsIT, JCCAC, Floating Projects</a></p>
						<span class="h2">Year</span>
						<p>2025</p>
					</div>
				</article>
				<aside>
					<ul>
						
						<li>
						<div class="video">
							
							<div class="embed-container">
  <iframe
      src="https://www.youtube.com/embed/PXdnfmSzHac"
      width="700"
      height="480"
      frameborder="0"
      allowfullscreen="">
  </iframe>
</div>
							
						</div>
						</li>
						
						<li>
						<div class="video">
							
							<div class="embed-container">
  <iframe
      src="https://www.youtube.com/embed/yMyR5DKjGA0"
      width="700"
      height="480"
      frameborder="0"
      allowfullscreen="">
  </iframe>
</div>
							
						</div>
						</li>
						
						
						<li>
							<img src="/assets/images/projects/temporal-spatial/intro02.jpg"" />
						</li>
						
						<li>
							<img src="/assets/images/projects/temporal-spatial/6-overview02.jpg"" />
						</li>
						
						<li>
							<img src="/assets/images/projects/temporal-spatial/7-progressive.jpg"" />
						</li>
						
						<li>
							<img src="/assets/images/projects/temporal-spatial/diagram01.jpg"" />
						</li>
						
						<li>
							<img src="/assets/images/projects/temporal-spatial/figs_video01.jpg"" />
						</li>
						
						<li>
							<img src="/assets/images/projects/temporal-spatial/figs_video03.jpg"" />
						</li>
						
					</ul>
				</aside>
			</div>
		</section>
		<section class="project-navigation">
			<div class="container">
				
				<a title="Previous Ronaldo's a poser! GenAI in Online Forums" href="/genai-forums/" class="prev">
					<span class="h2">Previous</span>
					<h2>Ronaldo's a poser! GenAI in Online Forums</h2>
				</a>
				
				
				<a title="Next Breaking the News" href="/breaking-the-news/" class="next">
					<span class="h2">Next</span>
					<h2>Breaking the News</h2>
				</a>
				
			</div>
		</section>
	</main>
	<footer class="footer">
	<div class="container">
		<section class="follow">
			<h2>Follow</h2>
			<ul>
				<li><a href= "https://www.scm.cityu.edu.hk/people/ray-lc" target="_blank">cityu school of creative media</a></li>
				<li><a href="https://raylc.org" target="_blank">portfolio by RAY LC</a></li>
				<li><a href="https://scholar.google.com/citations?user=8wM0urcAAAAJ&hl=en" target="_blank">google scholar</a></li>
				<li><a href="https://www.xiaohongshu.com/user/profile/61f93b40000000001000cd7f?xsec_token=YB2dLzT0iJyqYA3vipJu3xDQweZpMtgNal2Taf1sY6Kjk=&xsec_source=app_share&xhsshare=CopyLink&appuid=5fad3f9c0000000001006a56&apptime=1749432531&share_id=dcadb275de074e989b64b9e53b35449c" target="_blank">rednote</a></li>
				<li><a href="https://instagram.com/studiofornarrativespaces" target="_blank">instagram</a></li>
			</ul>
		</section>
		<section class="contact">
			<h2>Pages</h2>
<!-- when updating this, need to increment the numbers -->
<!-- below by one when new pages are added to pubs. -->
			<ul>
				<li><a href="/pubs/">publications</a></li>
				<li><a href="/people/">people</a></li>
				<li><a href="/press/">press</a></li>
				<li><a href="/opportunities/">opportunities</a></li>
				<li><a href="http://localhost:4000">projects</a></li>
			</ul>
		</section>
	</div>
</footer>
	<script src="/assets/scripts/vendor/jquery-1.12.4.min.js"></script>
	<script src="/assets/scripts/vendor/scrollreveal.min.js"></script>
	<script src="/assets/scripts/vendor/sticky-kit.min.js"></script>
	<script src="/assets/scripts/project.js"></script>
</body>
</html>